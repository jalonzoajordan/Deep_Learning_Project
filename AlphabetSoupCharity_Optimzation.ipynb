{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "675b05a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>Jan-99</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        EIN                                      NAME APPLICATION_TYPE  \\\n",
       "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
       "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
       "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
       "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
       "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
       "\n",
       "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
       "0       Independent          C1000    ProductDev   Association       1   \n",
       "1       Independent          C2000  Preservation  Co-operative       1   \n",
       "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
       "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
       "4       Independent          C1000     Heathcare         Trust       1   \n",
       "\n",
       "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
       "0              0                      N     5000              1  \n",
       "1         Jan-99                      N   108590              1  \n",
       "2              0                      N     5000              0  \n",
       "3    10000-24999                      N     6692              1  \n",
       "4  100000-499999                      N   142590              1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "#  Import and read the charity_data.csv.\n",
    "import pandas as pd \n",
    "application_df = pd.read_csv(\"../Resources/charity_data.csv\")\n",
    "application_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5c6cb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>AFFILIATION_CompanySponsored</th>\n",
       "      <th>AFFILIATION_Independent</th>\n",
       "      <th>CLASSIFICATION_C1000</th>\n",
       "      <th>CLASSIFICATION_C2000</th>\n",
       "      <th>CLASSIFICATION_C2100</th>\n",
       "      <th>USE_CASE_CommunityServ</th>\n",
       "      <th>USE_CASE_Preservation</th>\n",
       "      <th>ORGANIZATION_Association</th>\n",
       "      <th>ORGANIZATION_Trust</th>\n",
       "      <th>INCOME_AMT_0</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2816</th>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2928</th>\n",
       "      <td>7287</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10155</th>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20518</th>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29590</th>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_T3  \\\n",
       "2816      5000              1                    1   \n",
       "2928      7287              1                    1   \n",
       "10155     5000              1                    1   \n",
       "20518     5000              0                    1   \n",
       "29590     5000              0                    1   \n",
       "\n",
       "       AFFILIATION_CompanySponsored  AFFILIATION_Independent  \\\n",
       "2816                              1                        0   \n",
       "2928                              0                        1   \n",
       "10155                             0                        1   \n",
       "20518                             1                        0   \n",
       "29590                             0                        1   \n",
       "\n",
       "       CLASSIFICATION_C1000  CLASSIFICATION_C2000  CLASSIFICATION_C2100  \\\n",
       "2816                      0                     1                     0   \n",
       "2928                      1                     0                     0   \n",
       "10155                     1                     0                     0   \n",
       "20518                     0                     0                     1   \n",
       "29590                     1                     0                     0   \n",
       "\n",
       "       USE_CASE_CommunityServ  USE_CASE_Preservation  \\\n",
       "2816                        1                      0   \n",
       "2928                        0                      1   \n",
       "10155                       0                      1   \n",
       "20518                       1                      0   \n",
       "29590                       0                      1   \n",
       "\n",
       "       ORGANIZATION_Association  ORGANIZATION_Trust  INCOME_AMT_0  \\\n",
       "2816                          0                   1             1   \n",
       "2928                          0                   1             0   \n",
       "10155                         0                   1             0   \n",
       "20518                         1                   0             1   \n",
       "29590                         1                   0             1   \n",
       "\n",
       "       INCOME_AMT_10000-24999  INCOME_AMT_25000-99999  \\\n",
       "2816                        0                       0   \n",
       "2928                        0                       1   \n",
       "10155                       1                       0   \n",
       "20518                       0                       0   \n",
       "29590                       0                       0   \n",
       "\n",
       "       SPECIAL_CONSIDERATIONS_N  SPECIAL_CONSIDERATIONS_Y  \n",
       "2816                          1                         0  \n",
       "2928                          0                         1  \n",
       "10155                         1                         0  \n",
       "20518                         1                         0  \n",
       "29590                         1                         0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preprocess the dataset like you did in Step 1, taking into account any modifications to optimize the model.\n",
    "\n",
    "#For optimization, I removed the active statuses of 1 because the charities are not closed and may be successful in the future.\n",
    "application_cleaned_df = application_df[application_df['STATUS'] == 0]\n",
    "\n",
    "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'. Also drop status since it only has one value now\n",
    "application_cleaned_df.drop(['EIN', 'NAME', 'STATUS'], axis=1, inplace = True)\n",
    "\n",
    "# Convert categorical data to numeric with `pd.get_dummies`\n",
    "app_dummies_df = pd.get_dummies(application_cleaned_df)\n",
    "app_dummies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d3f194c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "X = app_dummies_df.drop(['IS_SUCCESSFUL'], axis=1)\n",
    "y = app_dummies_df['IS_SUCCESSFUL']\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "603a805b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3830871f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 20)                340       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 20)                420       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 781\n",
      "Trainable params: 781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Design a neural network model, taking into account any modifications that will optimize the model to achieve higher than 75% accuracy.\n",
    "\n",
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "features = len(X_train_scaled[0])\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=20, activation=\"relu\", input_dim=features))\n",
    "\n",
    "# Second hidden layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=20, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b6319d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1888a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 0.8841 - accuracy: 0.3333\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8598 - accuracy: 0.3333\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8371 - accuracy: 0.3333\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8149 - accuracy: 0.3333\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7931 - accuracy: 0.3333\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.7729 - accuracy: 0.3333\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7536 - accuracy: 0.3333\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.7348 - accuracy: 0.3333\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7164 - accuracy: 0.3333\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6986 - accuracy: 0.3333\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6812 - accuracy: 0.3333\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6636 - accuracy: 0.3333\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6465 - accuracy: 0.3333\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6298 - accuracy: 0.3333\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.6134 - accuracy: 0.6667\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5976 - accuracy: 0.6667\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5822 - accuracy: 0.6667\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5671 - accuracy: 0.6667\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5527 - accuracy: 0.6667\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5386 - accuracy: 0.6667\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5249 - accuracy: 0.6667\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.6667\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4984 - accuracy: 0.6667\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4857 - accuracy: 0.6667\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4732 - accuracy: 0.6667\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.6667\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.6667\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.6667\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.6667\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4110 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3976 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3845 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3715 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3593 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3476 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3358 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3242 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3127 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3016 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2907 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2802 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2699 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2600 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2411 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2327 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2247 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2169 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2095 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2022 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67506a09",
   "metadata": {},
   "source": [
    "Seeing the network quickly come to an accuracy of 1 brings the concern that we removed relevant data during cleanup. Initially, we had 43 features. When checking below, we see that by removing the open charities we are down to 16. This is because charity categorizations utilized haven't been used in a closed scenario. Recreating and running again below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c2024ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81c8a1b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T12</th>\n",
       "      <th>APPLICATION_TYPE_T13</th>\n",
       "      <th>APPLICATION_TYPE_T14</th>\n",
       "      <th>APPLICATION_TYPE_T15</th>\n",
       "      <th>APPLICATION_TYPE_T17</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>INCOME_AMT_Jan-99</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATUS  ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_T10  APPLICATION_TYPE_T12  \\\n",
       "0       1     5000              1                     1                     0   \n",
       "1       1   108590              1                     0                     0   \n",
       "2       1     5000              0                     0                     0   \n",
       "3       1     6692              1                     0                     0   \n",
       "4       1   142590              1                     0                     0   \n",
       "\n",
       "   APPLICATION_TYPE_T13  APPLICATION_TYPE_T14  APPLICATION_TYPE_T15  \\\n",
       "0                     0                     0                     0   \n",
       "1                     0                     0                     0   \n",
       "2                     0                     0                     0   \n",
       "3                     0                     0                     0   \n",
       "4                     0                     0                     0   \n",
       "\n",
       "   APPLICATION_TYPE_T17  APPLICATION_TYPE_T19  ...  INCOME_AMT_10000-24999  \\\n",
       "0                     0                     0  ...                       0   \n",
       "1                     0                     0  ...                       0   \n",
       "2                     0                     0  ...                       0   \n",
       "3                     0                     0  ...                       1   \n",
       "4                     0                     0  ...                       0   \n",
       "\n",
       "   INCOME_AMT_100000-499999  INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  \\\n",
       "0                         0                   0                 0   \n",
       "1                         0                   0                 0   \n",
       "2                         0                   0                 0   \n",
       "3                         0                   0                 0   \n",
       "4                         1                   0                 0   \n",
       "\n",
       "   INCOME_AMT_25000-99999  INCOME_AMT_50M+  INCOME_AMT_5M-10M  \\\n",
       "0                       0                0                  0   \n",
       "1                       0                0                  0   \n",
       "2                       0                0                  0   \n",
       "3                       0                0                  0   \n",
       "4                       0                0                  0   \n",
       "\n",
       "   INCOME_AMT_Jan-99  SPECIAL_CONSIDERATIONS_N  SPECIAL_CONSIDERATIONS_Y  \n",
       "0                  0                         1                         0  \n",
       "1                  1                         1                         0  \n",
       "2                  0                         1                         0  \n",
       "3                  0                         1                         0  \n",
       "4                  0                         1                         0  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#REDO CLEANUP\n",
    "\n",
    "#This time for optimization, I did not remove any charities based on open status. Instead, I removed the classification identifiers since it is an arbitrary categorization.\n",
    "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
    "application_cleaned_df = application_df.drop(['EIN', 'NAME', 'CLASSIFICATION'], axis=1)\n",
    "\n",
    "# Convert categorical data to numeric with `pd.get_dummies`\n",
    "app_dummies_df = pd.get_dummies(application_cleaned_df)\n",
    "app_dummies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cceba17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "X = app_dummies_df.drop(['IS_SUCCESSFUL'], axis=1)\n",
    "y = app_dummies_df['IS_SUCCESSFUL']\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47a49abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4281cbba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify that we didn't clear too many features this time\n",
    "features = len(X_train_scaled[0])\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773fdd88",
   "metadata": {},
   "source": [
    "NOTE: Rather than losing 2/3 of the features after splitting the data, we now have 2 additional features. This means our model will have more data to work with. This is also because we did not remove the lower values and the unused charities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "644399be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 100)               4600      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,801\n",
      "Trainable params: 14,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=100, activation=\"relu\", input_dim=features))\n",
    "\n",
    "# Second hidden layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=100, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9066d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec9bb59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "804/804 [==============================] - 1s 792us/step - loss: 0.5787 - accuracy: 0.7209\n",
      "Epoch 2/50\n",
      "804/804 [==============================] - 1s 780us/step - loss: 0.5706 - accuracy: 0.7273\n",
      "Epoch 3/50\n",
      "804/804 [==============================] - 1s 778us/step - loss: 0.5686 - accuracy: 0.7265\n",
      "Epoch 4/50\n",
      "804/804 [==============================] - 1s 776us/step - loss: 0.5666 - accuracy: 0.7280\n",
      "Epoch 5/50\n",
      "804/804 [==============================] - 1s 777us/step - loss: 0.5656 - accuracy: 0.7289\n",
      "Epoch 6/50\n",
      "804/804 [==============================] - 1s 788us/step - loss: 0.5651 - accuracy: 0.7294\n",
      "Epoch 7/50\n",
      "804/804 [==============================] - 1s 773us/step - loss: 0.5645 - accuracy: 0.7298\n",
      "Epoch 8/50\n",
      "804/804 [==============================] - 1s 780us/step - loss: 0.5640 - accuracy: 0.7288\n",
      "Epoch 9/50\n",
      "804/804 [==============================] - 1s 768us/step - loss: 0.5640 - accuracy: 0.7291\n",
      "Epoch 10/50\n",
      "804/804 [==============================] - 1s 768us/step - loss: 0.5635 - accuracy: 0.7287\n",
      "Epoch 11/50\n",
      "804/804 [==============================] - 1s 768us/step - loss: 0.5636 - accuracy: 0.7298\n",
      "Epoch 12/50\n",
      "804/804 [==============================] - 1s 780us/step - loss: 0.5630 - accuracy: 0.7297\n",
      "Epoch 13/50\n",
      "804/804 [==============================] - 1s 781us/step - loss: 0.5628 - accuracy: 0.7306\n",
      "Epoch 14/50\n",
      "804/804 [==============================] - 1s 798us/step - loss: 0.5625 - accuracy: 0.7299\n",
      "Epoch 15/50\n",
      "804/804 [==============================] - 1s 813us/step - loss: 0.5620 - accuracy: 0.7299\n",
      "Epoch 16/50\n",
      "804/804 [==============================] - 1s 806us/step - loss: 0.5615 - accuracy: 0.7309\n",
      "Epoch 17/50\n",
      "804/804 [==============================] - 1s 890us/step - loss: 0.5620 - accuracy: 0.7311\n",
      "Epoch 18/50\n",
      "804/804 [==============================] - 1s 816us/step - loss: 0.5615 - accuracy: 0.7312\n",
      "Epoch 19/50\n",
      "804/804 [==============================] - 1s 788us/step - loss: 0.5616 - accuracy: 0.7309\n",
      "Epoch 20/50\n",
      "804/804 [==============================] - 1s 792us/step - loss: 0.5616 - accuracy: 0.7307\n",
      "Epoch 21/50\n",
      "804/804 [==============================] - 1s 811us/step - loss: 0.5612 - accuracy: 0.7313\n",
      "Epoch 22/50\n",
      "804/804 [==============================] - 1s 803us/step - loss: 0.5606 - accuracy: 0.7318\n",
      "Epoch 23/50\n",
      "804/804 [==============================] - 1s 795us/step - loss: 0.5608 - accuracy: 0.7314\n",
      "Epoch 24/50\n",
      "804/804 [==============================] - 1s 787us/step - loss: 0.5606 - accuracy: 0.7311\n",
      "Epoch 25/50\n",
      "804/804 [==============================] - 1s 784us/step - loss: 0.5604 - accuracy: 0.7319\n",
      "Epoch 26/50\n",
      "804/804 [==============================] - 1s 793us/step - loss: 0.5605 - accuracy: 0.7314\n",
      "Epoch 27/50\n",
      "804/804 [==============================] - 1s 801us/step - loss: 0.5602 - accuracy: 0.7310\n",
      "Epoch 28/50\n",
      "804/804 [==============================] - 1s 795us/step - loss: 0.5599 - accuracy: 0.7325\n",
      "Epoch 29/50\n",
      "804/804 [==============================] - 1s 791us/step - loss: 0.5598 - accuracy: 0.7312\n",
      "Epoch 30/50\n",
      "804/804 [==============================] - 1s 795us/step - loss: 0.5597 - accuracy: 0.7324\n",
      "Epoch 31/50\n",
      "804/804 [==============================] - 1s 791us/step - loss: 0.5595 - accuracy: 0.7322\n",
      "Epoch 32/50\n",
      "804/804 [==============================] - 1s 795us/step - loss: 0.5599 - accuracy: 0.7320\n",
      "Epoch 33/50\n",
      "804/804 [==============================] - 1s 797us/step - loss: 0.5596 - accuracy: 0.7321\n",
      "Epoch 34/50\n",
      "804/804 [==============================] - 1s 796us/step - loss: 0.5592 - accuracy: 0.7318\n",
      "Epoch 35/50\n",
      "804/804 [==============================] - 1s 801us/step - loss: 0.5594 - accuracy: 0.7325\n",
      "Epoch 36/50\n",
      "804/804 [==============================] - 1s 790us/step - loss: 0.5592 - accuracy: 0.7320\n",
      "Epoch 37/50\n",
      "804/804 [==============================] - 1s 777us/step - loss: 0.5592 - accuracy: 0.7325\n",
      "Epoch 38/50\n",
      "804/804 [==============================] - 1s 785us/step - loss: 0.5590 - accuracy: 0.7323\n",
      "Epoch 39/50\n",
      "804/804 [==============================] - 1s 792us/step - loss: 0.5588 - accuracy: 0.7325\n",
      "Epoch 40/50\n",
      "804/804 [==============================] - 1s 777us/step - loss: 0.5589 - accuracy: 0.7327\n",
      "Epoch 41/50\n",
      "804/804 [==============================] - 1s 781us/step - loss: 0.5589 - accuracy: 0.7321\n",
      "Epoch 42/50\n",
      "804/804 [==============================] - 1s 782us/step - loss: 0.5585 - accuracy: 0.7322\n",
      "Epoch 43/50\n",
      "804/804 [==============================] - 1s 775us/step - loss: 0.5587 - accuracy: 0.7320\n",
      "Epoch 44/50\n",
      "804/804 [==============================] - 1s 779us/step - loss: 0.5582 - accuracy: 0.7327\n",
      "Epoch 45/50\n",
      "804/804 [==============================] - 1s 781us/step - loss: 0.5585 - accuracy: 0.7325\n",
      "Epoch 46/50\n",
      "804/804 [==============================] - 1s 786us/step - loss: 0.5582 - accuracy: 0.7323\n",
      "Epoch 47/50\n",
      "804/804 [==============================] - 1s 778us/step - loss: 0.5583 - accuracy: 0.7326\n",
      "Epoch 48/50\n",
      "804/804 [==============================] - 1s 785us/step - loss: 0.5582 - accuracy: 0.7325\n",
      "Epoch 49/50\n",
      "804/804 [==============================] - 1s 785us/step - loss: 0.5580 - accuracy: 0.7325\n",
      "Epoch 50/50\n",
      "804/804 [==============================] - 1s 785us/step - loss: 0.5583 - accuracy: 0.7327\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "549244e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.5786 - accuracy: 0.7188 - 240ms/epoch - 894us/step\n",
      "Loss: 0.578606367111206, Accuracy: 0.7188338041305542\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81733614",
   "metadata": {},
   "source": [
    "We are fairly close to our accuracy goal of 75%. For this third attempt, we will also perform the cleanup done on the fringe and zero values that was done prior, now that we have identified relevant columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "668af171",
   "metadata": {},
   "outputs": [],
   "source": [
    "#REDO CLEANUP TAKE 2\n",
    "\n",
    "#This time for optimization, I did not remove any charities based on open status. Instead, I removed the classification identifiers since it is an arbitrary categorization.\n",
    "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
    "application_cleaned_df = application_df.drop(['EIN', 'NAME', 'CLASSIFICATION'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2156e51d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T3       27037\n",
       "T4        1542\n",
       "T6        1216\n",
       "T5        1173\n",
       "T19       1065\n",
       "T8         737\n",
       "T7         725\n",
       "T10        528\n",
       "Other      276\n",
       "Name: APPLICATION_TYPE, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a cutoff value and create a list of application types to be replaced\n",
    "\n",
    "# Look at APPLICATION_TYPE value counts for binning\n",
    "app_bins = application_df['APPLICATION_TYPE'].value_counts()\n",
    "\n",
    "# use the variable name `application_types_to_replace`\n",
    "application_types_to_replace = app_bins.loc[app_bins < 500].index.tolist()\n",
    "\n",
    "# Replace in dataframe\n",
    "for app in application_types_to_replace:\n",
    "    application_cleaned_df['APPLICATION_TYPE'] = application_cleaned_df['APPLICATION_TYPE'].replace(app,\"Other\")\n",
    "\n",
    "# Check to make sure binning was successful\n",
    "application_cleaned_df['APPLICATION_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "864d399c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "Other     2261\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "Name: CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at CLASSIFICATION value counts for binning\n",
    "class_bins = application_df['CLASSIFICATION'].value_counts()\n",
    "\n",
    "# Choose a cutoff value and create a list of classifications to be replaced\n",
    "# use the variable name `classifications_to_replace`\n",
    "classifications_to_replace = class_bins.loc[class_bins < 1000].index.tolist()\n",
    "\n",
    "# Replace in dataframe\n",
    "for cls in classifications_to_replace:\n",
    "    application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls,\"Other\")\n",
    "    \n",
    "# Check to make sure binning was successful\n",
    "application_df['CLASSIFICATION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3cb58745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>INCOME_AMT_Jan-99</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATUS  ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  \\\n",
       "0       1     5000              1                       0   \n",
       "1       1   108590              1                       0   \n",
       "2       1     5000              0                       0   \n",
       "3       1     6692              1                       0   \n",
       "4       1   142590              1                       0   \n",
       "\n",
       "   APPLICATION_TYPE_T10  APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  \\\n",
       "0                     1                     0                    0   \n",
       "1                     0                     0                    1   \n",
       "2                     0                     0                    0   \n",
       "3                     0                     0                    1   \n",
       "4                     0                     0                    1   \n",
       "\n",
       "   APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  ...  \\\n",
       "0                    0                    0                    0  ...   \n",
       "1                    0                    0                    0  ...   \n",
       "2                    0                    1                    0  ...   \n",
       "3                    0                    0                    0  ...   \n",
       "4                    0                    0                    0  ...   \n",
       "\n",
       "   INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  INCOME_AMT_10M-50M  \\\n",
       "0                       0                         0                   0   \n",
       "1                       0                         0                   0   \n",
       "2                       0                         0                   0   \n",
       "3                       1                         0                   0   \n",
       "4                       0                         1                   0   \n",
       "\n",
       "   INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  INCOME_AMT_50M+  \\\n",
       "0                 0                       0                0   \n",
       "1                 0                       0                0   \n",
       "2                 0                       0                0   \n",
       "3                 0                       0                0   \n",
       "4                 0                       0                0   \n",
       "\n",
       "   INCOME_AMT_5M-10M  INCOME_AMT_Jan-99  SPECIAL_CONSIDERATIONS_N  \\\n",
       "0                  0                  0                         1   \n",
       "1                  0                  1                         1   \n",
       "2                  0                  0                         1   \n",
       "3                  0                  0                         1   \n",
       "4                  0                  0                         1   \n",
       "\n",
       "   SPECIAL_CONSIDERATIONS_Y  \n",
       "0                         0  \n",
       "1                         0  \n",
       "2                         0  \n",
       "3                         0  \n",
       "4                         0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert categorical data to numeric with `pd.get_dummies`\n",
    "app_dummies_df = pd.get_dummies(application_cleaned_df)\n",
    "app_dummies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f8d195a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "X = app_dummies_df.drop(['IS_SUCCESSFUL'], axis=1)\n",
    "y = app_dummies_df['IS_SUCCESSFUL']\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4544e9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ec1945f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify that we didn't clear too many features this time\n",
    "features = len(X_train_scaled[0])\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "322ded05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 100)               3800      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,001\n",
      "Trainable params: 14,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=100, activation=\"relu\", input_dim=features))\n",
    "\n",
    "# Second hidden layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=100, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b2e1c87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c0fe3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "804/804 [==============================] - 1s 817us/step - loss: 0.5838 - accuracy: 0.7169\n",
      "Epoch 2/50\n",
      "804/804 [==============================] - 1s 802us/step - loss: 0.5736 - accuracy: 0.7248\n",
      "Epoch 3/50\n",
      "804/804 [==============================] - 1s 792us/step - loss: 0.5720 - accuracy: 0.7231\n",
      "Epoch 4/50\n",
      "804/804 [==============================] - 1s 792us/step - loss: 0.5701 - accuracy: 0.7236\n",
      "Epoch 5/50\n",
      "804/804 [==============================] - 1s 788us/step - loss: 0.5687 - accuracy: 0.7257\n",
      "Epoch 6/50\n",
      "804/804 [==============================] - 1s 791us/step - loss: 0.5684 - accuracy: 0.7248\n",
      "Epoch 7/50\n",
      "804/804 [==============================] - 1s 822us/step - loss: 0.5675 - accuracy: 0.7246\n",
      "Epoch 8/50\n",
      "804/804 [==============================] - 1s 796us/step - loss: 0.5672 - accuracy: 0.7258\n",
      "Epoch 9/50\n",
      "804/804 [==============================] - 1s 806us/step - loss: 0.5672 - accuracy: 0.7258\n",
      "Epoch 10/50\n",
      "804/804 [==============================] - 1s 802us/step - loss: 0.5664 - accuracy: 0.7274\n",
      "Epoch 11/50\n",
      "804/804 [==============================] - 1s 796us/step - loss: 0.5660 - accuracy: 0.7257\n",
      "Epoch 12/50\n",
      "804/804 [==============================] - 1s 792us/step - loss: 0.5662 - accuracy: 0.7268\n",
      "Epoch 13/50\n",
      "804/804 [==============================] - 1s 792us/step - loss: 0.5657 - accuracy: 0.7271\n",
      "Epoch 14/50\n",
      "804/804 [==============================] - 1s 789us/step - loss: 0.5651 - accuracy: 0.7274\n",
      "Epoch 15/50\n",
      "804/804 [==============================] - 1s 791us/step - loss: 0.5649 - accuracy: 0.7268\n",
      "Epoch 16/50\n",
      "804/804 [==============================] - 1s 790us/step - loss: 0.5649 - accuracy: 0.7271\n",
      "Epoch 17/50\n",
      "804/804 [==============================] - 1s 808us/step - loss: 0.5648 - accuracy: 0.7269\n",
      "Epoch 18/50\n",
      "804/804 [==============================] - 1s 790us/step - loss: 0.5643 - accuracy: 0.7276\n",
      "Epoch 19/50\n",
      "804/804 [==============================] - 1s 786us/step - loss: 0.5642 - accuracy: 0.7268\n",
      "Epoch 20/50\n",
      "804/804 [==============================] - 1s 796us/step - loss: 0.5640 - accuracy: 0.7284\n",
      "Epoch 21/50\n",
      "804/804 [==============================] - 1s 796us/step - loss: 0.5638 - accuracy: 0.7279\n",
      "Epoch 22/50\n",
      "804/804 [==============================] - 1s 799us/step - loss: 0.5640 - accuracy: 0.7273\n",
      "Epoch 23/50\n",
      "804/804 [==============================] - 1s 782us/step - loss: 0.5639 - accuracy: 0.7268\n",
      "Epoch 24/50\n",
      "804/804 [==============================] - 1s 785us/step - loss: 0.5634 - accuracy: 0.7278\n",
      "Epoch 25/50\n",
      "804/804 [==============================] - 1s 777us/step - loss: 0.5629 - accuracy: 0.7279\n",
      "Epoch 26/50\n",
      "804/804 [==============================] - 1s 785us/step - loss: 0.5635 - accuracy: 0.7280\n",
      "Epoch 27/50\n",
      "804/804 [==============================] - 1s 793us/step - loss: 0.5631 - accuracy: 0.7282\n",
      "Epoch 28/50\n",
      "804/804 [==============================] - 1s 791us/step - loss: 0.5631 - accuracy: 0.7280\n",
      "Epoch 29/50\n",
      "804/804 [==============================] - 1s 788us/step - loss: 0.5627 - accuracy: 0.7279\n",
      "Epoch 30/50\n",
      "804/804 [==============================] - 1s 787us/step - loss: 0.5631 - accuracy: 0.7283\n",
      "Epoch 31/50\n",
      "804/804 [==============================] - 1s 787us/step - loss: 0.5626 - accuracy: 0.7285\n",
      "Epoch 32/50\n",
      "804/804 [==============================] - 1s 782us/step - loss: 0.5625 - accuracy: 0.7282\n",
      "Epoch 33/50\n",
      "804/804 [==============================] - 1s 790us/step - loss: 0.5623 - accuracy: 0.7283\n",
      "Epoch 34/50\n",
      "804/804 [==============================] - 1s 781us/step - loss: 0.5624 - accuracy: 0.7275\n",
      "Epoch 35/50\n",
      "804/804 [==============================] - 1s 790us/step - loss: 0.5626 - accuracy: 0.7282\n",
      "Epoch 36/50\n",
      "804/804 [==============================] - 1s 790us/step - loss: 0.5620 - accuracy: 0.7296\n",
      "Epoch 37/50\n",
      "804/804 [==============================] - 1s 797us/step - loss: 0.5621 - accuracy: 0.7280\n",
      "Epoch 38/50\n",
      "804/804 [==============================] - 1s 799us/step - loss: 0.5621 - accuracy: 0.7275\n",
      "Epoch 39/50\n",
      "804/804 [==============================] - 1s 786us/step - loss: 0.5621 - accuracy: 0.7283\n",
      "Epoch 40/50\n",
      "804/804 [==============================] - 1s 784us/step - loss: 0.5619 - accuracy: 0.7285\n",
      "Epoch 41/50\n",
      "804/804 [==============================] - 1s 797us/step - loss: 0.5618 - accuracy: 0.7276\n",
      "Epoch 42/50\n",
      "804/804 [==============================] - 1s 790us/step - loss: 0.5619 - accuracy: 0.7281\n",
      "Epoch 43/50\n",
      "804/804 [==============================] - 1s 798us/step - loss: 0.5616 - accuracy: 0.7287\n",
      "Epoch 44/50\n",
      "804/804 [==============================] - 1s 797us/step - loss: 0.5616 - accuracy: 0.7290\n",
      "Epoch 45/50\n",
      "804/804 [==============================] - 1s 794us/step - loss: 0.5619 - accuracy: 0.7282\n",
      "Epoch 46/50\n",
      "804/804 [==============================] - 1s 785us/step - loss: 0.5615 - accuracy: 0.7286\n",
      "Epoch 47/50\n",
      "804/804 [==============================] - 1s 786us/step - loss: 0.5613 - accuracy: 0.7290\n",
      "Epoch 48/50\n",
      "804/804 [==============================] - 1s 782us/step - loss: 0.5612 - accuracy: 0.7287\n",
      "Epoch 49/50\n",
      "804/804 [==============================] - 1s 783us/step - loss: 0.5612 - accuracy: 0.7284\n",
      "Epoch 50/50\n",
      "804/804 [==============================] - 1s 791us/step - loss: 0.5614 - accuracy: 0.7290\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3d8a9161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "804/804 [==============================] - 1s 817us/step - loss: 0.5610 - accuracy: 0.7287\n",
      "Epoch 2/100\n",
      "804/804 [==============================] - 1s 803us/step - loss: 0.5612 - accuracy: 0.7291\n",
      "Epoch 3/100\n",
      "804/804 [==============================] - 1s 786us/step - loss: 0.5610 - accuracy: 0.7282\n",
      "Epoch 4/100\n",
      "804/804 [==============================] - 1s 788us/step - loss: 0.5606 - accuracy: 0.7291\n",
      "Epoch 5/100\n",
      "804/804 [==============================] - 1s 786us/step - loss: 0.5605 - accuracy: 0.7293\n",
      "Epoch 6/100\n",
      "804/804 [==============================] - 1s 797us/step - loss: 0.5610 - accuracy: 0.7289\n",
      "Epoch 7/100\n",
      "804/804 [==============================] - 1s 801us/step - loss: 0.5615 - accuracy: 0.7285\n",
      "Epoch 8/100\n",
      "804/804 [==============================] - 1s 808us/step - loss: 0.5604 - accuracy: 0.7288\n",
      "Epoch 9/100\n",
      "804/804 [==============================] - 1s 816us/step - loss: 0.5611 - accuracy: 0.7277\n",
      "Epoch 10/100\n",
      "804/804 [==============================] - 1s 832us/step - loss: 0.5605 - accuracy: 0.7295\n",
      "Epoch 11/100\n",
      "804/804 [==============================] - 1s 814us/step - loss: 0.5604 - accuracy: 0.7299\n",
      "Epoch 12/100\n",
      "804/804 [==============================] - 1s 833us/step - loss: 0.5602 - accuracy: 0.7289\n",
      "Epoch 13/100\n",
      "804/804 [==============================] - 1s 831us/step - loss: 0.5609 - accuracy: 0.7293\n",
      "Epoch 14/100\n",
      "804/804 [==============================] - 1s 814us/step - loss: 0.5606 - accuracy: 0.7294\n",
      "Epoch 15/100\n",
      "804/804 [==============================] - 1s 817us/step - loss: 0.5603 - accuracy: 0.7296\n",
      "Epoch 16/100\n",
      "804/804 [==============================] - 1s 811us/step - loss: 0.5604 - accuracy: 0.7291\n",
      "Epoch 17/100\n",
      "804/804 [==============================] - 1s 794us/step - loss: 0.5608 - accuracy: 0.7292\n",
      "Epoch 18/100\n",
      "804/804 [==============================] - 1s 812us/step - loss: 0.5602 - accuracy: 0.7295\n",
      "Epoch 19/100\n",
      "804/804 [==============================] - 1s 797us/step - loss: 0.5600 - accuracy: 0.7292\n",
      "Epoch 20/100\n",
      "804/804 [==============================] - 1s 793us/step - loss: 0.5604 - accuracy: 0.7292\n",
      "Epoch 21/100\n",
      "804/804 [==============================] - 1s 792us/step - loss: 0.5600 - accuracy: 0.7294\n",
      "Epoch 22/100\n",
      "804/804 [==============================] - 1s 796us/step - loss: 0.5602 - accuracy: 0.7290\n",
      "Epoch 23/100\n",
      "804/804 [==============================] - 1s 794us/step - loss: 0.5604 - accuracy: 0.7290\n",
      "Epoch 24/100\n",
      "804/804 [==============================] - 1s 800us/step - loss: 0.5600 - accuracy: 0.7291\n",
      "Epoch 25/100\n",
      "804/804 [==============================] - 1s 818us/step - loss: 0.5604 - accuracy: 0.7294\n",
      "Epoch 26/100\n",
      "804/804 [==============================] - 1s 797us/step - loss: 0.5602 - accuracy: 0.7293\n",
      "Epoch 27/100\n",
      "804/804 [==============================] - 1s 796us/step - loss: 0.5620 - accuracy: 0.7290\n",
      "Epoch 28/100\n",
      "804/804 [==============================] - 1s 795us/step - loss: 0.5602 - accuracy: 0.7292\n",
      "Epoch 29/100\n",
      "804/804 [==============================] - 1s 797us/step - loss: 0.5600 - accuracy: 0.7294\n",
      "Epoch 30/100\n",
      "804/804 [==============================] - 1s 798us/step - loss: 0.5600 - accuracy: 0.7294\n",
      "Epoch 31/100\n",
      "804/804 [==============================] - 1s 814us/step - loss: 0.5598 - accuracy: 0.7294\n",
      "Epoch 32/100\n",
      "804/804 [==============================] - 1s 804us/step - loss: 0.5598 - accuracy: 0.7294\n",
      "Epoch 33/100\n",
      "804/804 [==============================] - 1s 809us/step - loss: 0.5597 - accuracy: 0.7292\n",
      "Epoch 34/100\n",
      "804/804 [==============================] - 1s 807us/step - loss: 0.5597 - accuracy: 0.7294\n",
      "Epoch 35/100\n",
      "804/804 [==============================] - 1s 818us/step - loss: 0.5600 - accuracy: 0.7298\n",
      "Epoch 36/100\n",
      "804/804 [==============================] - 1s 826us/step - loss: 0.5597 - accuracy: 0.7294\n",
      "Epoch 37/100\n",
      "804/804 [==============================] - 1s 842us/step - loss: 0.5600 - accuracy: 0.7295\n",
      "Epoch 38/100\n",
      "804/804 [==============================] - 1s 822us/step - loss: 0.5597 - accuracy: 0.7303\n",
      "Epoch 39/100\n",
      "804/804 [==============================] - 1s 817us/step - loss: 0.5594 - accuracy: 0.7296\n",
      "Epoch 40/100\n",
      "804/804 [==============================] - 1s 818us/step - loss: 0.5607 - accuracy: 0.7286\n",
      "Epoch 41/100\n",
      "804/804 [==============================] - 1s 812us/step - loss: 0.5595 - accuracy: 0.7291\n",
      "Epoch 42/100\n",
      "804/804 [==============================] - 1s 801us/step - loss: 0.5597 - accuracy: 0.7294\n",
      "Epoch 43/100\n",
      "804/804 [==============================] - 1s 801us/step - loss: 0.5598 - accuracy: 0.7297\n",
      "Epoch 44/100\n",
      "804/804 [==============================] - 1s 798us/step - loss: 0.5592 - accuracy: 0.7287\n",
      "Epoch 45/100\n",
      "804/804 [==============================] - 1s 800us/step - loss: 0.5597 - accuracy: 0.7294\n",
      "Epoch 46/100\n",
      "804/804 [==============================] - 1s 801us/step - loss: 0.5600 - accuracy: 0.7291\n",
      "Epoch 47/100\n",
      "804/804 [==============================] - 1s 802us/step - loss: 0.5593 - accuracy: 0.7297\n",
      "Epoch 48/100\n",
      "804/804 [==============================] - 1s 801us/step - loss: 0.5596 - accuracy: 0.7296\n",
      "Epoch 49/100\n",
      "804/804 [==============================] - 1s 803us/step - loss: 0.5593 - accuracy: 0.7293\n",
      "Epoch 50/100\n",
      "804/804 [==============================] - 1s 805us/step - loss: 0.5597 - accuracy: 0.7296\n",
      "Epoch 51/100\n",
      "804/804 [==============================] - 1s 803us/step - loss: 0.5594 - accuracy: 0.7298\n",
      "Epoch 52/100\n",
      "804/804 [==============================] - 1s 801us/step - loss: 0.5597 - accuracy: 0.7297\n",
      "Epoch 53/100\n",
      "804/804 [==============================] - 1s 817us/step - loss: 0.5594 - accuracy: 0.7296\n",
      "Epoch 54/100\n",
      "804/804 [==============================] - 1s 821us/step - loss: 0.5603 - accuracy: 0.7292\n",
      "Epoch 55/100\n",
      "804/804 [==============================] - 1s 861us/step - loss: 0.5594 - accuracy: 0.7287\n",
      "Epoch 56/100\n",
      "804/804 [==============================] - 1s 841us/step - loss: 0.5595 - accuracy: 0.7291\n",
      "Epoch 57/100\n",
      "804/804 [==============================] - 1s 812us/step - loss: 0.5592 - accuracy: 0.7295\n",
      "Epoch 58/100\n",
      "804/804 [==============================] - 1s 842us/step - loss: 0.5593 - accuracy: 0.7293\n",
      "Epoch 59/100\n",
      "804/804 [==============================] - 1s 814us/step - loss: 0.5595 - accuracy: 0.7296\n",
      "Epoch 60/100\n",
      "804/804 [==============================] - 1s 812us/step - loss: 0.5592 - accuracy: 0.7298\n",
      "Epoch 61/100\n",
      "804/804 [==============================] - 1s 807us/step - loss: 0.5594 - accuracy: 0.7295\n",
      "Epoch 62/100\n",
      "804/804 [==============================] - 1s 805us/step - loss: 0.5592 - accuracy: 0.7295\n",
      "Epoch 63/100\n",
      "804/804 [==============================] - 1s 800us/step - loss: 0.5593 - accuracy: 0.7293\n",
      "Epoch 64/100\n",
      "804/804 [==============================] - 1s 813us/step - loss: 0.5597 - accuracy: 0.7297\n",
      "Epoch 65/100\n",
      "804/804 [==============================] - 1s 818us/step - loss: 0.5703 - accuracy: 0.7293\n",
      "Epoch 66/100\n",
      "804/804 [==============================] - 1s 819us/step - loss: 0.5611 - accuracy: 0.7297\n",
      "Epoch 67/100\n",
      "804/804 [==============================] - 1s 800us/step - loss: 0.5588 - accuracy: 0.7300\n",
      "Epoch 68/100\n",
      "804/804 [==============================] - 1s 792us/step - loss: 0.5587 - accuracy: 0.7295\n",
      "Epoch 69/100\n",
      "804/804 [==============================] - 1s 795us/step - loss: 0.5589 - accuracy: 0.7301\n",
      "Epoch 70/100\n",
      "804/804 [==============================] - 1s 787us/step - loss: 0.5587 - accuracy: 0.7295\n",
      "Epoch 71/100\n",
      "804/804 [==============================] - 1s 796us/step - loss: 0.5588 - accuracy: 0.7296\n",
      "Epoch 72/100\n",
      "804/804 [==============================] - 1s 798us/step - loss: 0.5590 - accuracy: 0.7299\n",
      "Epoch 73/100\n",
      "804/804 [==============================] - 1s 800us/step - loss: 0.5588 - accuracy: 0.7299\n",
      "Epoch 74/100\n",
      "804/804 [==============================] - 1s 803us/step - loss: 0.5590 - accuracy: 0.7297\n",
      "Epoch 75/100\n",
      "804/804 [==============================] - 1s 799us/step - loss: 0.5592 - accuracy: 0.7301\n",
      "Epoch 76/100\n",
      "804/804 [==============================] - 1s 809us/step - loss: 0.5589 - accuracy: 0.7296\n",
      "Epoch 77/100\n",
      "804/804 [==============================] - 1s 808us/step - loss: 0.5592 - accuracy: 0.7294\n",
      "Epoch 78/100\n",
      "804/804 [==============================] - 1s 801us/step - loss: 0.5588 - accuracy: 0.7292\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "804/804 [==============================] - 1s 802us/step - loss: 0.5587 - accuracy: 0.7298\n",
      "Epoch 80/100\n",
      "804/804 [==============================] - 1s 796us/step - loss: 0.5586 - accuracy: 0.7298\n",
      "Epoch 81/100\n",
      "804/804 [==============================] - 1s 811us/step - loss: 0.5589 - accuracy: 0.7292\n",
      "Epoch 82/100\n",
      "804/804 [==============================] - 1s 808us/step - loss: 0.5587 - accuracy: 0.7300\n",
      "Epoch 83/100\n",
      "804/804 [==============================] - 1s 808us/step - loss: 0.5589 - accuracy: 0.7299\n",
      "Epoch 84/100\n",
      "804/804 [==============================] - 1s 817us/step - loss: 0.5592 - accuracy: 0.7298\n",
      "Epoch 85/100\n",
      "804/804 [==============================] - 1s 815us/step - loss: 0.5587 - accuracy: 0.7297\n",
      "Epoch 86/100\n",
      "804/804 [==============================] - 1s 808us/step - loss: 0.5588 - accuracy: 0.7300\n",
      "Epoch 87/100\n",
      "804/804 [==============================] - 1s 797us/step - loss: 0.5588 - accuracy: 0.7299\n",
      "Epoch 88/100\n",
      "804/804 [==============================] - 1s 792us/step - loss: 0.5605 - accuracy: 0.7293\n",
      "Epoch 89/100\n",
      "804/804 [==============================] - 1s 798us/step - loss: 0.5589 - accuracy: 0.7304\n",
      "Epoch 90/100\n",
      "804/804 [==============================] - 1s 793us/step - loss: 0.5587 - accuracy: 0.7295\n",
      "Epoch 91/100\n",
      "804/804 [==============================] - 1s 802us/step - loss: 0.5585 - accuracy: 0.7299\n",
      "Epoch 92/100\n",
      "804/804 [==============================] - 1s 786us/step - loss: 0.5589 - accuracy: 0.7299\n",
      "Epoch 93/100\n",
      "804/804 [==============================] - 1s 796us/step - loss: 0.5584 - accuracy: 0.7289\n",
      "Epoch 94/100\n",
      "804/804 [==============================] - 1s 783us/step - loss: 0.5588 - accuracy: 0.7296\n",
      "Epoch 95/100\n",
      "804/804 [==============================] - 1s 795us/step - loss: 0.5598 - accuracy: 0.7304\n",
      "Epoch 96/100\n",
      "804/804 [==============================] - 1s 788us/step - loss: 0.5588 - accuracy: 0.7292\n",
      "Epoch 97/100\n",
      "804/804 [==============================] - 1s 777us/step - loss: 0.5585 - accuracy: 0.7294\n",
      "Epoch 98/100\n",
      "804/804 [==============================] - 1s 785us/step - loss: 0.5605 - accuracy: 0.7299\n",
      "Epoch 99/100\n",
      "804/804 [==============================] - 1s 790us/step - loss: 0.5586 - accuracy: 0.7292\n",
      "Epoch 100/100\n",
      "804/804 [==============================] - 1s 786us/step - loss: 0.5582 - accuracy: 0.7291\n"
     ]
    }
   ],
   "source": [
    "# Train the model again with more epochs to see if we can reach 75% goal\n",
    "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f6d11811",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.5897 - accuracy: 0.7266 - 150ms/epoch - 560us/step\n",
      "Loss: 0.5896536707878113, Accuracy: 0.7266472578048706\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa10468",
   "metadata": {},
   "source": [
    "After corrections, we still only improved by just under 2% from our pre-optimized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b70d2441",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save and export your results to an HDF5 file\n",
    "nn_model.save(\"AlphabetSoupCharity_Optimization.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9e0abe59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualization for report\n",
    "# Create a DataFrame containing training history\n",
    "history_df = pd.DataFrame(fit_model.history, index=range(1,len(fit_model.history[\"loss\"])+1))\n",
    "\n",
    "# Plot the accuracy\n",
    "history_df.plot(y=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2a626d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
